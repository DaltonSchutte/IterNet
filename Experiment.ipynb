{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Experiment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f1YcdJWf_XW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sbn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtQ3AN78f_Xi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16*4*4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        out = self.fc3(x)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1tEBg0xf_Xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IterNet(nn.Module):\n",
        "    def __init__(self, iter_depth=2):\n",
        "        super(IterNet, self).__init__()\n",
        "        \n",
        "        self.iter_depth = iter_depth\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.input = nn.Linear(16*4*4, 120)\n",
        "        self.iterative = nn.Linear(120, 120)\n",
        "        self.out = nn.Linear(120, 10)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.input(x))\n",
        "        \n",
        "        #Iterative Block\n",
        "        for i in range(self.iter_depth):\n",
        "            x = F.relu(self.iterative(self.iterative(x))+self.iterative(x))\n",
        "            \n",
        "        out = self.out(x)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixu6k38jf_X4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,),(0.5,))\n",
        "                               ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxM_1oEggPfe",
        "colab_type": "code",
        "outputId": "05b641e1-ff53-4ffd-d368-2a82421415b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaU3zqGJf_YC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT = './data'\n",
        "BATCH = 64\n",
        "\n",
        "train_data = datasets.MNIST(root=ROOT, download=True, train=True, transform=transform)\n",
        "test_data = datasets.MNIST(root=ROOT, download=True, train=False, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH, shuffle=True)\n",
        "\n",
        "loaders = {'train': train_loader,\n",
        "           'test': test_loader}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-e6c6Iif_YJ",
        "colab_type": "code",
        "outputId": "96b1dd96-c149-4906-da1e-5aee6e299338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "data_iter = iter(train_loader)\n",
        "images, labels = data_iter.next()\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "plt.imshow(images[0].squeeze())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd58f10ed68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhvVwAAKf_Yb",
        "colab_type": "code",
        "outputId": "99252990-e44b-4fea-841f-53dd9a8426c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "lenet = LeNet()\n",
        "print(lenet)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LeNet(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qVWhXwaf_Yh",
        "colab_type": "code",
        "outputId": "80cf72c0-4479-440b-bf47-1f2c0f3177fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "iternet = IterNet(iter_depth=2)\n",
        "print(iternet)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IterNet(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (input): Linear(in_features=256, out_features=120, bias=True)\n",
            "  (iterative): Linear(in_features=120, out_features=120, bias=True)\n",
            "  (out): Linear(in_features=120, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCNAgi85hGuU",
        "colab_type": "code",
        "outputId": "96931d5f-0e99-4dda-8ffd-de46b7bc3c19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_parameters = filter(lambda p: p.requires_grad, lenet.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "\n",
        "print(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZxJSlWThR5k",
        "colab_type": "code",
        "outputId": "f8e92f7a-cef0-4d76-9949-361dbb413132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_parameters = filter(lambda p: p.requires_grad, iternet.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "\n",
        "print(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPRNn99Ef_Yr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            nn.init.kaiming_normal_(m.weight)\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            nn.init.kaiming_normal_(m.weight)\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMIL7nX9f_Yy",
        "colab_type": "code",
        "outputId": "44f870c9-3b25-4cab-e40f-f1d1f0256a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RFVNPBKf_ZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(epochs, loaders, model, optimizer, criterion, device, verbose=True):\n",
        "    assert type(loaders) == dict and len(loaders) == 2, ValueError(\"Improper Loader dict\")\n",
        "    \n",
        "    model = model.to(device)\n",
        "    \n",
        "    train_losses = []\n",
        "    \n",
        "    for e in range(1, epochs+1):\n",
        "        train_loss = 0\n",
        "        \n",
        "        #Train loop\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * data.size(0)\n",
        "            train_losses.append(loss.item())\n",
        "            \n",
        "        train_loss = train_loss / len(loaders['train'])\n",
        "            \n",
        "        if verbose:\n",
        "            print(\"  Epoch {}\\n\\tTrain Loss: {:.4f}\".format(e, train_loss))\n",
        "        \n",
        "    return train_losses, model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQgqqrtUf_ZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(loaders, model, criterion, device):\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        test_loss + ((1 / (batch_idx+1)) * (loss.data - test_loss))\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "        \n",
        "    print('Test Loss: {:.4f}'.format(test_loss))\n",
        "    print('Test Accuracy: {:.2%}'.format(correct / total))\n",
        "    \n",
        "    return correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip6QYUHaf_ZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trial_evaluation(n_trials, epochs, loaders, model_name, device, iter_depth=2, verbose=False):\n",
        "    assert model_name in ['LeNet', 'IterNet'], ValueError('Invalid model type')\n",
        "\n",
        "    print(\"Testing {} instances of {} model for {} epochs per trial...\".format(n_trials,\n",
        "                                                                               model_name,\n",
        "                                                                               epochs\n",
        "                                                                              ))\n",
        "    \n",
        "    train_losses = []\n",
        "    trained_models = []\n",
        "    test_accuracies = []\n",
        "    \n",
        "    #Run trials\n",
        "    for trial in range(1, n_trials+1):\n",
        "        if model_name == 'LeNet':\n",
        "            model = LeNet()\n",
        "        elif model_name == 'IterNet':\n",
        "            model = IterNet(iter_depth=iter_depth)\n",
        "    \n",
        "        #Initialize weights with kaiming_normal\n",
        "        weights_init(model)\n",
        "        \n",
        "        #SGD with Nesterov Momentum and L2 weight decay\n",
        "        optimizer = optim.SGD(model.parameters(), \n",
        "                              lr=0.003,\n",
        "                              momentum=0.9,\n",
        "                              nesterov=True,\n",
        "                              weight_decay=1e-4\n",
        "                             )\n",
        "\n",
        "        #CrossEntropyLoss\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "        print(\"Trial: \", trial)\n",
        "        train_loss, trained_model = train_model(epochs, \n",
        "                                                loaders, \n",
        "                                                model, \n",
        "                                                optimizer, \n",
        "                                                criterion, \n",
        "                                                device, \n",
        "                                                verbose\n",
        "                                               )\n",
        "        test_accuracy = test_model(loaders,\n",
        "                                   trained_model,\n",
        "                                   criterion,\n",
        "                                   device\n",
        "                                  )\n",
        "        \n",
        "        train_losses.append(train_loss)\n",
        "        test_accuracies.append(test_accuracy)\n",
        "        trained_models.append(trained_model)\n",
        "    \n",
        "    return train_losses, test_accuracies, trained_models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAP5VWabj2_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRIALS = 7\n",
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYzJ6qAhkE66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xn8Rdt3f_ZQ",
        "colab_type": "code",
        "outputId": "e7d1c236-f392-4a78-a943-b55f81dd02ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "time_0 = time.time()\n",
        "_, LN_Accuracies, _ = trial_evaluation(TRIALS, EPOCHS, loaders, 'LeNet', device, verbose=True)\n",
        "time_elapsed = time.time()-time_0\n",
        "print(\"Total: {:.2f}\\tAverage: {:.2f}\".format(time_elapsed, time_elapsed/TRIALS))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing 7 instances of LeNet model for 10 epochs per trial...\n",
            "Trial:  1\n",
            "  Epoch 1\n",
            "\tTrain Loss: 16.2925\n",
            "  Epoch 2\n",
            "\tTrain Loss: 5.6579\n",
            "  Epoch 3\n",
            "\tTrain Loss: 4.1169\n",
            "  Epoch 4\n",
            "\tTrain Loss: 3.3693\n",
            "  Epoch 5\n",
            "\tTrain Loss: 2.8489\n",
            "  Epoch 6\n",
            "\tTrain Loss: 2.4326\n",
            "  Epoch 7\n",
            "\tTrain Loss: 2.1382\n",
            "  Epoch 8\n",
            "\tTrain Loss: 1.8797\n",
            "  Epoch 9\n",
            "\tTrain Loss: 1.6860\n",
            "  Epoch 10\n",
            "\tTrain Loss: 1.4972\n",
            "Test Loss: 0.0000\n",
            "Test Accuracy: 98.74%\n",
            "Trial:  2\n",
            "  Epoch 1\n",
            "\tTrain Loss: 16.6515\n",
            "  Epoch 2\n",
            "\tTrain Loss: 5.6186\n",
            "  Epoch 3\n",
            "\tTrain Loss: 4.0944\n",
            "  Epoch 4\n",
            "\tTrain Loss: 3.2980\n",
            "  Epoch 5\n",
            "\tTrain Loss: 2.7628\n",
            "  Epoch 6\n",
            "\tTrain Loss: 2.4261\n",
            "  Epoch 7\n",
            "\tTrain Loss: 2.1081\n",
            "  Epoch 8\n",
            "\tTrain Loss: 1.8988\n",
            "  Epoch 9\n",
            "\tTrain Loss: 1.6625\n",
            "  Epoch 10\n",
            "\tTrain Loss: 1.5350\n",
            "Test Loss: 0.0000\n",
            "Test Accuracy: 98.63%\n",
            "Trial:  3\n",
            "  Epoch 1\n",
            "\tTrain Loss: 17.6816\n",
            "  Epoch 2\n",
            "\tTrain Loss: 6.1127\n",
            "  Epoch 3\n",
            "\tTrain Loss: 4.4820\n",
            "  Epoch 4\n",
            "\tTrain Loss: 3.5951\n",
            "  Epoch 5\n",
            "\tTrain Loss: 3.0138\n",
            "  Epoch 6\n",
            "\tTrain Loss: 2.6330\n",
            "  Epoch 7\n",
            "\tTrain Loss: 2.2612\n",
            "  Epoch 8\n",
            "\tTrain Loss: 2.0321\n",
            "  Epoch 9\n",
            "\tTrain Loss: 1.7924\n",
            "  Epoch 10\n",
            "\tTrain Loss: 1.5765\n",
            "Test Loss: 0.0000\n",
            "Test Accuracy: 98.56%\n",
            "Trial:  4\n",
            "  Epoch 1\n",
            "\tTrain Loss: 21.0229\n",
            "  Epoch 2\n",
            "\tTrain Loss: 6.3723\n",
            "  Epoch 3\n",
            "\tTrain Loss: 4.5283\n",
            "  Epoch 4\n",
            "\tTrain Loss: 3.6278\n",
            "  Epoch 5\n",
            "\tTrain Loss: 2.9804\n",
            "  Epoch 6\n",
            "\tTrain Loss: 2.6392\n",
            "  Epoch 7\n",
            "\tTrain Loss: 2.2378\n",
            "  Epoch 8\n",
            "\tTrain Loss: 1.9509\n",
            "  Epoch 9\n",
            "\tTrain Loss: 1.7462\n",
            "  Epoch 10\n",
            "\tTrain Loss: 1.5748\n",
            "Test Loss: 0.0000\n",
            "Test Accuracy: 98.29%\n",
            "Trial:  5\n",
            "  Epoch 1\n",
            "\tTrain Loss: 19.4428\n",
            "  Epoch 2\n",
            "\tTrain Loss: 6.7286\n",
            "  Epoch 3\n",
            "\tTrain Loss: 4.7815\n",
            "  Epoch 4\n",
            "\tTrain Loss: 3.7903\n",
            "  Epoch 5\n",
            "\tTrain Loss: 3.2411\n",
            "  Epoch 6\n",
            "\tTrain Loss: 2.7560\n",
            "  Epoch 7\n",
            "\tTrain Loss: 2.3913\n",
            "  Epoch 8\n",
            "\tTrain Loss: 2.1074\n",
            "  Epoch 9\n",
            "\tTrain Loss: 1.9095\n",
            "  Epoch 10\n",
            "\tTrain Loss: 1.6766\n",
            "Test Loss: 0.0000\n",
            "Test Accuracy: 98.65%\n",
            "Trial:  6\n",
            "  Epoch 1\n",
            "\tTrain Loss: 17.6845\n",
            "  Epoch 2\n",
            "\tTrain Loss: 6.0343\n",
            "  Epoch 3\n",
            "\tTrain Loss: 4.4986\n",
            "  Epoch 4\n",
            "\tTrain Loss: 3.7039\n",
            "  Epoch 5\n",
            "\tTrain Loss: 3.1134\n",
            "  Epoch 6\n",
            "\tTrain Loss: 2.6932\n",
            "  Epoch 7\n",
            "\tTrain Loss: 2.3442\n",
            "  Epoch 8\n",
            "\tTrain Loss: 2.1453\n",
            "  Epoch 9\n",
            "\tTrain Loss: 1.9231\n",
            "  Epoch 10\n",
            "\tTrain Loss: 1.6850\n",
            "Test Loss: 0.0000\n",
            "Test Accuracy: 98.50%\n",
            "Trial:  7\n",
            "  Epoch 1\n",
            "\tTrain Loss: 16.9098\n",
            "  Epoch 2\n",
            "\tTrain Loss: 5.6053\n",
            "  Epoch 3\n",
            "\tTrain Loss: 4.0877\n",
            "  Epoch 4\n",
            "\tTrain Loss: 3.3350\n",
            "  Epoch 5\n",
            "\tTrain Loss: 2.8222\n",
            "  Epoch 6\n",
            "\tTrain Loss: 2.4443\n",
            "  Epoch 7\n",
            "\tTrain Loss: 2.1414\n",
            "  Epoch 8\n",
            "\tTrain Loss: 1.8818\n",
            "  Epoch 9\n",
            "\tTrain Loss: 1.6802\n",
            "  Epoch 10\n",
            "\tTrain Loss: 1.4843\n",
            "Test Loss: 0.0000\n",
            "Test Accuracy: 98.68%\n",
            "Total: 639.10\tAverage: 91.30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pep46LHBf_ZU",
        "colab_type": "code",
        "outputId": "22bf46d4-96af-42f0-a66b-429a8bc86be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "time_0 = time.time()\n",
        "_, IN2_Accuracies, _ = trial_evaluation(TRIALS, EPOCHS, loaders, 'IterNet', device, verbose=True)\n",
        "time_elapsed = time.time()-time_0\n",
        "print(\"Total: {:.2f}\\tAverage: {:.2f}\".format(time_elapsed, time_elapsed/TRIALS))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing 7 instances of IterNet model for 10 epochs per trial...\n",
            "Trial:  1\n",
            "  Epoch 1\n",
            "\tTrain Loss: 16.4225\n",
            "  Epoch 2\n",
            "\tTrain Loss: 5.2418\n",
            "  Epoch 3\n",
            "\tTrain Loss: 3.9495\n",
            "  Epoch 4\n",
            "\tTrain Loss: 3.0507\n",
            "  Epoch 5\n",
            "\tTrain Loss: 2.5643\n",
            "  Epoch 6\n",
            "\tTrain Loss: 2.1921\n",
            "  Epoch 7\n",
            "\tTrain Loss: 1.8600\n",
            "  Epoch 8\n",
            "\tTrain Loss: 1.6313\n",
            "  Epoch 9\n",
            "\tTrain Loss: 1.4037\n",
            "  Epoch 10\n",
            "\tTrain Loss: 1.2573\n",
            "Test Loss: 0.0000\n",
            "Test Accuracy: 98.40%\n",
            "Trial:  2\n",
            "  Epoch 1\n",
            "\tTrain Loss: 26.4764\n",
            "  Epoch 2\n",
            "\tTrain Loss: 7.3255\n",
            "  Epoch 3\n",
            "\tTrain Loss: 5.3947\n",
            "  Epoch 4\n",
            "\tTrain Loss: 4.3045\n",
            "  Epoch 5\n",
            "\tTrain Loss: 3.6404\n",
            "  Epoch 6\n",
            "\tTrain Loss: 3.0728\n",
            "  Epoch 7\n",
            "\tTrain Loss: 2.7488\n",
            "  Epoch 8\n",
            "\tTrain Loss: 2.5284\n",
            "  Epoch 9\n",
            "\tTrain Loss: 2.1888\n",
            "  Epoch 10\n",
            "\tTrain Loss: 2.0026\n",
            "Test Loss: 0.0000\n",
            "Test Accuracy: 98.24%\n",
            "Trial:  3\n",
            "  Epoch 1\n",
            "\tTrain Loss: 39.7468\n",
            "  Epoch 2\n",
            "\tTrain Loss: 8.5665\n",
            "  Epoch 3\n",
            "\tTrain Loss: 6.3181\n",
            "  Epoch 4\n",
            "\tTrain Loss: 5.1419\n",
            "  Epoch 5\n",
            "\tTrain Loss: 4.3552\n",
            "  Epoch 6\n",
            "\tTrain Loss: 3.8359\n",
            "  Epoch 7\n",
            "\tTrain Loss: 3.4453\n",
            "  Epoch 8\n",
            "\tTrain Loss: 3.0197\n",
            "  Epoch 9\n",
            "\tTrain Loss: 2.8654\n",
            "  Epoch 10\n",
            "\tTrain Loss: 2.5882\n",
            "Test Loss: 0.0000\n",
            "Test Accuracy: 98.12%\n",
            "Trial:  4\n",
            "  Epoch 1\n",
            "\tTrain Loss: 21.7228\n",
            "  Epoch 2\n",
            "\tTrain Loss: 7.4508\n",
            "  Epoch 3\n",
            "\tTrain Loss: 5.6490\n",
            "  Epoch 4\n",
            "\tTrain Loss: 4.5155\n",
            "  Epoch 5\n",
            "\tTrain Loss: 3.7568\n",
            "  Epoch 6\n",
            "\tTrain Loss: 3.3962\n",
            "  Epoch 7\n",
            "\tTrain Loss: 2.9254\n",
            "  Epoch 8\n",
            "\tTrain Loss: 2.5926\n",
            "  Epoch 9\n",
            "\tTrain Loss: 2.2986\n",
            "  Epoch 10\n",
            "\tTrain Loss: 2.2486\n",
            "Test Loss: 0.0000\n",
            "Test Accuracy: 98.33%\n",
            "Trial:  5\n",
            "  Epoch 1\n",
            "\tTrain Loss: 17.4471\n",
            "  Epoch 2\n",
            "\tTrain Loss: 5.7177\n",
            "  Epoch 3\n",
            "\tTrain Loss: 4.3770\n",
            "  Epoch 4\n",
            "\tTrain Loss: 3.5311\n",
            "  Epoch 5\n",
            "\tTrain Loss: 3.0727\n",
            "  Epoch 6\n",
            "\tTrain Loss: 2.5488\n",
            "  Epoch 7\n",
            "\tTrain Loss: 2.2988\n",
            "  Epoch 8\n",
            "\tTrain Loss: 1.9190\n",
            "  Epoch 9\n",
            "\tTrain Loss: 1.7436\n",
            "  Epoch 10\n",
            "\tTrain Loss: 1.5593\n",
            "Test Loss: 0.0000\n",
            "Test Accuracy: 98.55%\n",
            "Trial:  6\n",
            "  Epoch 1\n",
            "\tTrain Loss: 16.1633\n",
            "  Epoch 2\n",
            "\tTrain Loss: 5.0755\n",
            "  Epoch 3\n",
            "\tTrain Loss: 3.7684\n",
            "  Epoch 4\n",
            "\tTrain Loss: 3.1156\n",
            "  Epoch 5\n",
            "\tTrain Loss: 2.4945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP5HqeSPhkar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_0 = time.time()\n",
        "_, IN3_Accuracies, _ = trial_evaluation(TRIALS, EPOCHS, loaders, 'IterNet', device, iter_depth=3, verbose=False)\n",
        "time_elapsed = time.time()-time_0\n",
        "print(\"Total: {:.2f}\\tAverage: {:.2f}\".format(time_elapsed, time_elapsed/TRIALS))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56Qc2UeHjgu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_0 = time.time()\n",
        "_, IN1_Accuracies, _ = trial_evaluation(TRIALS, EPOCHS, loaders, 'IterNet', device, iter_depth=1, verbose=False)\n",
        "time_elapsed = time.time()-time_0\n",
        "print(\"Total: {:.2f}\\tAverage: {:.2f}\".format(time_elapsed, time_elapsed/TRIALS))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaTHAAKijrfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IN1_Accuracies = np.array(IN1_Accuracies)\n",
        "\n",
        "print(\"Max: \", np.max(IN1_Accuracies))\n",
        "print(\"Min: \", np.min(IN1_Accuracies))\n",
        "print(\"Mean: \", np.mean(IN1_Accuracies))\n",
        "print(\"SDev: \", np.std(IN1_Accuracies))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQyvZVJGntjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IN2_Accuracies = np.array(IN2_Accuracies)\n",
        "\n",
        "print(\"Max: \", np.max(IN2_Accuracies))\n",
        "print(\"Min: \", np.min(IN2_Accuracies))\n",
        "print(\"Mean: \", np.mean(IN2_Accuracies))\n",
        "print(\"SDev: \", np.std(IN2_Accuracies))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3x95z2mnwie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IN3_Accuracies = np.array(IN3_Accuracies)\n",
        "\n",
        "print(\"Max: \", np.max(IN3_Accuracies))\n",
        "print(\"Min: \", np.min(IN3_Accuracies))\n",
        "print(\"Mean: \", np.mean(IN3_Accuracies))\n",
        "print(\"SDev: \", np.std(IN3_Accuracies))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT5ZEotQn1IV",
        "colab_type": "code",
        "outputId": "4d566ff1-14f5-4f3c-c2c7-1f8617a28ad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "LN_Accuracies = np.array(LN_Accuracies)\n",
        "\n",
        "print(\"Max: \", np.max(LN_Accuracies))\n",
        "print(\"Min: \", np.min(LN_Accuracies))\n",
        "print(\"Mean: \", np.mean(LN_Accuracies))\n",
        "print(\"SDev: \", np.std(LN_Accuracies))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max:  0.9874\n",
            "Min:  0.9829\n",
            "Mean:  0.9857857142857143\n",
            "SDev:  0.0013829870068892641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r76AgZGpfAyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}